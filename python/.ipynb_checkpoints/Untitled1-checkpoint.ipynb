{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, accuracy_score,f1_score,precision_score,recall_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(filename):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    y = df.y\n",
    "    X = df.drop(columns=['y'])\n",
    "    return (X, y)\n",
    "\n",
    "def get_beta_in_select_file(beta, filename):\n",
    "    X_temp, y = process_csv(filename)\n",
    "    X = beta[ X_temp.index ]\n",
    "    y = pd.DataFrame(y)\n",
    "    return X.T, y\n",
    "\n",
    "def get_x_y_data(filename, num_probe_return=False):\n",
    "    df = pd.read_csv(filename, header=0, index_col=0)\n",
    "    probe_data_t = np.array(df)\n",
    "    num_probes = len(df.columns)-1\n",
    "    X = probe_data_t[0:, 0:num_probes]\n",
    "    y = df['y']\n",
    "    if (num_probe_return == False):\n",
    "        return X,y\n",
    "    else:\n",
    "        return X, y, num_probes\n",
    "    \n",
    "def get_oneHotCode_matrix(labels, encoder):\n",
    "    integer_encoded = encoder.fit_transform(labels)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    labels_one_hot = keras.utils.to_categorical(integer_encoded, num_classes)\n",
    "    return labels_one_hot\n",
    "\n",
    "def select_probes(data, sd_cutoff):\n",
    "    probes = data.T\n",
    "    probes['STD'] = probes.std(axis=1)\n",
    "    above_threshold = probes[probes[\"STD\"] > sd_cutoff]\n",
    "    print(\"shape in select_probes\", above_threshold.shape)\n",
    "    return above_threshold.drop(columns='STD').T\n",
    "\n",
    "def match_probes(ref_data, data_to_be_matched):\n",
    "    df = data_to_be_matched.loc[:, ref_data.columns.values]\n",
    "    return df\n",
    "\n",
    "def create_model(n_inputs,n_classes):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Dense(1000, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(keras.layers.Dense(500, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(keras.layers.Dense(n_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss= 'categorical_crossentropy', \n",
    "                  metrics=['accuracy', 'Precision','Recall', 'mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_label2(mod, feature, x, y, encoder):\n",
    "    x_test_temp = match_probes(feature, x)\n",
    "    Xtest = np.asarray(x_test_temp).astype(np.float32)\n",
    "    pred_scores = mod.predict(Xtest)\n",
    "    pred_int_code = np.argmax(pred_scores, axis=1)\n",
    "    y_pred = encoder.inverse_transform(pred_int_code)\n",
    "    return y_pred\n",
    "\n",
    "def accuracy_per_class(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.unique(y_true)\n",
    "    per_class_accuracies = cm.diagonal()/cm.sum(axis=1)\n",
    "    per_class_acc_wKeys = {}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        per_class_acc_wKeys[cls] = per_class_accuracies[idx]\n",
    "    return per_class_acc_wKeys\n",
    "\n",
    "\n",
    "def create_per_class_acc_df(class_acc, seed, dataset_name):\n",
    "    d = pd.DataFrame(columns = ['Seed', 'Dataset'])\n",
    "    d = d.append(class_acc, ignore_index=True)\n",
    "    d['Seed'] = seed\n",
    "    d['Dataset'] = dataset_name\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate2(data_x, data_y, cv, encoder, cls_weight, sd_cutoff):\n",
    "    '''\n",
    "    features are selectiving for the training data set after each CV split\n",
    "    '''\n",
    "    cvscores = []\n",
    "    fold = 1\n",
    "    for train_index,test_index in cv.split(data_x, data_y):\n",
    "        #print(\"X_cv shape = \", data_x.shape, \"; y_cv shape = \", data_y.shape)\n",
    "        x_train_temp = select_probes(data_x.iloc[train_index, :], sd_cutoff)\n",
    "        x_test_temp = match_probes(x_train_temp, data_x.iloc[test_index, :])\n",
    "        x_train = np.asarray(x_train_temp).astype(np.float32) ###convert to np.float32 to be used in model.fit\n",
    "        x_test = np.asarray(x_test_temp).astype(np.float32)\n",
    "        y_train,y_test = data_y.iloc[train_index, :], data_y.iloc[test_index, :]\n",
    "        y_train_encode = get_oneHotCode_matrix(y_train.values.ravel(), encoder)\n",
    "        y_test_encode = get_oneHotCode_matrix(y_test.values.ravel(), encoder)\n",
    "\n",
    "        n_inputs = len(x_train_temp.columns)\n",
    "        model = create_model(n_inputs, len(np.unique(y_test))) \n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold} ...')\n",
    "        y_test_intcode = encoder.fit_transform(y_test.values.ravel())\n",
    "        #val_sample_weights = class_weight.compute_sample_weight(cls_weight, y_test_intcode)\n",
    "        hist = model.fit(x_train, y_train_encode,epochs=20, batch_size=50, verbose=0)\n",
    "        scores = model.evaluate(x_test, y_test_encode, verbose=0)\n",
    "        cvscores.append(scores)\n",
    "        fold = fold+1\n",
    "    return model, x_train_temp, pd.DataFrame(cvscores, columns= model.metrics_names)\n",
    "\n",
    "def evaluate_against_test_set2(mod, feature, x_test, y_test, encoder, cls_weight):\n",
    "    y_pred = get_pred_label2(mod, feature, x_test, y_test, encoder)\n",
    "    y_test_encode = encoder.fit_transform(y_test.values.ravel())\n",
    "    #test_sample_weights = class_weight.compute_sample_weight(cls_weight, y_test_encode)\n",
    "    \n",
    "    acc=accuracy_score(y_test,y_pred).round(3)\n",
    "    bal_acc=balanced_accuracy_score(y_test,y_pred).round(3)\n",
    "    rec=recall_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    prec=precision_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    f1=f1_score(y_test,y_pred, average='weighted').round(3)\n",
    "    per_class_acc = accuracy_per_class(y_test, y_pred)\n",
    "    \n",
    "    return (acc, bal_acc, rec, prec, f1, per_class_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_result(p, df):\n",
    "    s = pd.Series(p, index=df.columns)\n",
    "    return df.append(s, ignore_index=True)\n",
    "\n",
    "def append_testset_results(df, r, seed_name, dataset_name):\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'accuracy', r[0]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'balanced_acc', r[1]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'recall_weighted', r[2]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'precision_weighted', r[3]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'f1_weighted', r[4]], df)\n",
    "    return df\n",
    "\n",
    "def apply_CV(mod, cv, X, y):\n",
    "    return cross_validate(mod, X, y, cv=cv, scoring=['balanced_accuracy', 'accuracy', 'recall_weighted'])\n",
    "\n",
    "def append_cv_results(df, r, seed_name, dataset_name):\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'loss', r['loss'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'accuracy', r['accuracy'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'precision', r['precision'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'recall', r['recall'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'mae', r['mae'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'mse', r['mse'].mean()], df)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(seed, beta, rkfold, encoder, cls_weight, sd_cutoff=0.3):\n",
    "    print('1. Read files (seed={})'.format(seed))\n",
    "       \n",
    "    file70LC= '/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_70percLC.csv'.format(seed)\n",
    "    \n",
    "    \n",
    "    file35_GSELC ='/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_35perc_LCgse109379.csv'.format(seed)\n",
    "    \n",
    "    file70LC_GSE = '/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_70LC_gse109379.csv'.format(seed)\n",
    "    file70_GSELC = '/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_70perc_gse109379LC.csv'.format(seed)\n",
    "    file70LC_GSELC = '/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_70LC_gse109379LC.csv'.format(seed)\n",
    "    fileHoldOut = '/Volumes/qtran/Semisupervised_Learning/python/data_class/seed{}_holdOutTest.csv'.format(seed)\n",
    "    #########\n",
    "    print('\\tReading', file70LC)\n",
    "    X70LC, y70LC = get_beta_in_select_file(beta, file70LC)\n",
    "    \n",
    "    ##\n",
    "    print('\\tReading', file35_GSELC)\n",
    "    X35gseLC, y35gseLC = get_beta_in_select_file(beta, file35_GSELC)\n",
    "    ##\n",
    "    print('\\tReading', file70LC_GSE)\n",
    "    X70LCgse, y70LCgse = get_beta_in_select_file(beta, file70LC_GSE)\n",
    "    print('\\tReading', file70_GSELC)\n",
    "    X70gseLC, y70gseLC = get_beta_in_select_file(beta, file70_GSELC)\n",
    "    print('\\tReading', file70LC_GSELC)\n",
    "    XLC, yLC = get_beta_in_select_file(beta, file70LC_GSELC)\n",
    "    \n",
    "    print('\\tReading', fileHoldOut)\n",
    "    xitest, yitest = get_beta_in_select_file(beta, fileHoldOut)\n",
    "    ###################\n",
    "    \n",
    "    print('4. Evaluate model with 70% LC')    \n",
    "    nnmodel70LC, features70LC, result_cv_70LC = cross_validate2(X70LC, y70LC, rkfold, encoder, cls_weight, sd_cutoff=sd_cutoff)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70LC = evaluate_against_test_set2(nnmodel70LC, features70LC, xitest, yitest, encoder, cls_weight)\n",
    "    \n",
    "       \n",
    "    print('6. Evaluate model with 35% data with High confident GSE109379')\n",
    "    nnmodel35gseLC, features35gseLC, result_cv_35gseLC = cross_validate2(X35gseLC, y35gseLC, rkfold, encoder, cls_weight, sd_cutoff=sd_cutoff)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_35gseLC = evaluate_against_test_set2(nnmodel35gseLC, features35gseLC, xitest, yitest, encoder, cls_weight)\n",
    "       \n",
    "    ##########    \n",
    "             \n",
    "    print('8. Evaluate model with 70% LC + GSE109379')\n",
    "    nnmodel70LCgse, features70LCgse, result_cv_70LCgse = cross_validate2(X70LCgse, y70LCgse, rkfold, encoder, cls_weight, sd_cutoff=sd_cutoff)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70LCgse = evaluate_against_test_set2(nnmodel70LCgse, features70LCgse, xitest, yitest, encoder, cls_weight)\n",
    "\n",
    "    print('9. Evaluate model with 70% + LC GSE90496 ')    \n",
    "    nnmodel70gseLC, features70gseLC, result_cv_70gseLC = cross_validate2(X70gseLC, y70gseLC, rkfold, encoder, cls_weight, sd_cutoff=sd_cutoff)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70gseLC = evaluate_against_test_set2(nnmodel70gseLC,features70gseLC, xitest, yitest, encoder, cls_weight)\n",
    "      \n",
    "    print('10. Evaluate model with LC pseudo-labeled data')    \n",
    "    nnmodelLC, featuresLC, result_cv_LC = cross_validate2(XLC, yLC, rkfold, encoder, cls_weight, sd_cutoff=sd_cutoff)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_LC = evaluate_against_test_set2(nnmodelLC, featuresLC, xitest, yitest, encoder, cls_weight)\n",
    "\n",
    "    \n",
    "    \n",
    "    #########\n",
    "    \n",
    "    print('6. Store results.')\n",
    "    df = pd.DataFrame(data=[], columns=['Seed','Dataset','Validation','Metric','Value'])\n",
    "       \n",
    "    df = append_cv_results(df, result_cv_70LC, seed, '70LC')\n",
    "    df = append_testset_results(df, result_ts_70LC, seed, '70LC')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_35gseLC, seed, '35_gseLC')\n",
    "    df = append_testset_results(df, result_ts_35gseLC, seed, '35_gseLC')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70LCgse, seed, '70LC_GSE')\n",
    "    df = append_testset_results(df, result_ts_70LCgse, seed, '70LC_GSE')\n",
    "    df = append_cv_results(df, result_cv_70gseLC, seed, '70_gseLC')\n",
    "    df = append_testset_results(df, result_ts_70gseLC, seed, '70_gseLC')\n",
    "    df = append_cv_results(df, result_cv_LC, seed, 'LC')\n",
    "    df = append_testset_results(df, result_ts_LC, seed, 'LC')\n",
    "    \n",
    "    \n",
    "    df_class_acc = pd.DataFrame(columns = ['Seed', 'Dataset'])\n",
    "    \n",
    "    df_class = create_per_class_acc_df(result_ts_70LC[5], seed, '70LC')\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_35gseLC[5], seed, '35_gseLC'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70LCgse[5], seed, '70LC_GSE'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70gseLC[5], seed, '70_gseLC'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_LC[5], seed, 'LC'))\n",
    "\n",
    "    \n",
    "    return (df, df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in beta file\n",
      "(438370, 3905)\n",
      "            GSM2940725_10003886252_R05C02  GSM2940726_10003886252_R06C02  \\\n",
      "V1                                                                         \n",
      "cg00001349                       0.904303                       0.952826   \n",
      "cg00001583                       0.081005                       0.435887   \n",
      "cg00002028                       0.102884                       0.086820   \n",
      "cg00002719                       0.007451                       0.007405   \n",
      "cg00002837                       0.468567                       0.852895   \n",
      "\n",
      "            GSM2940727_10003886253_R03C02  GSM2940728_10003886253_R04C01  \\\n",
      "V1                                                                         \n",
      "cg00001349                       0.900135                       0.912227   \n",
      "cg00001583                       0.424067                       0.118561   \n",
      "cg00002028                       0.074596                       0.081241   \n",
      "cg00002719                       0.010628                       0.018836   \n",
      "cg00002837                       0.561962                       0.719024   \n",
      "\n",
      "            GSM2940729_10003886253_R04C02  GSM2940730_10003886256_R01C01  \\\n",
      "V1                                                                         \n",
      "cg00001349                       0.937049                       0.717190   \n",
      "cg00001583                       0.128671                       0.048978   \n",
      "cg00002028                       0.066769                       0.088387   \n",
      "cg00002719                       0.016165                       0.020122   \n",
      "cg00002837                       0.856630                       0.573318   \n",
      "\n",
      "            GSM2940731_10003886256_R02C02  GSM2940732_10003886256_R05C02  \\\n",
      "V1                                                                         \n",
      "cg00001349                       0.880989                       0.878788   \n",
      "cg00001583                       0.187442                       0.256505   \n",
      "cg00002028                       0.143354                       0.109463   \n",
      "cg00002719                       0.017712                       0.022660   \n",
      "cg00002837                       0.366759                       0.466488   \n",
      "\n",
      "            GSM2940733_10003886256_R06C01  GSM2940734_10003886258_R01C01  \n",
      "V1                                                                        \n",
      "cg00001349                       0.886704                       0.931285  \n",
      "cg00001583                       0.061832                       0.582311  \n",
      "cg00002028                       0.253490                       0.206799  \n",
      "cg00002719                       0.012477                       0.006048  \n",
      "cg00002837                       0.595415                       0.491636  \n",
      "Finish dropping column\n",
      "(438370, 3905)\n",
      "400.045263\n",
      "start seed= 1\n",
      "1. Read files (seed=1)\n",
      "\tReading /research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/data_class/seed1_70percLC.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/data_class/seed1_70percLC.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3e1d0004230a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start seed=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_weight_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_cutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/result_NN_balanced_LCClass_seed{}_GSE109379_rand{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moutput_per_class_file\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/output_acc_perClass/result_NN_bal_acc_perLCClass_seed{}_GSE109379_rand{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-2c4b219aab6b>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(seed, beta, rkfold, encoder, cls_weight, sd_cutoff)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tReading'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile70LC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mX70LC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my70LC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_beta_in_select_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile70LC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-238f560b750c>\u001b[0m in \u001b[0;36mget_beta_in_select_file\u001b[0;34m(beta, filename)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_beta_in_select_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-238f560b750c>\u001b[0m in \u001b[0;36mprocess_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/data_class/seed1_70percLC.csv'"
     ]
    }
   ],
   "source": [
    "class_label = '/Volumes/qtran/Semisupervised_Learning/python/raw_data/GSE90496_methylation_class_label.csv'\n",
    "\n",
    "y = pd.read_csv(class_label, header=0, names=['labels'])\n",
    "###create a labelencoder to transform str classes to integer classes \n",
    "###and use the labelencoder to reverse transform to get the str labels throughout\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y['labels'])\n",
    "###\n",
    "    \n",
    "###calculate class weights to let the model to pay attention to the under-represented classes\n",
    "cls_weights = class_weight.compute_class_weight(\"balanced\", classes=np.unique(integer_encoded), y=integer_encoded)\n",
    "cls_weight_dict = {}\n",
    "for cls in np.unique(integer_encoded):\n",
    "    cls_weight_dict[cls] = cls_weights[cls].round(3)\n",
    "    \n",
    "\n",
    "tic = time.process_time()\n",
    "print(\"Read in beta file\")\n",
    "beta_file = '/Volumes/qtran/Semisupervised_Learning/python/raw_data/beta_1104_validation_allRef_filtered_noNA.csv'\n",
    "beta = pd.read_csv(beta_file, index_col=0)\n",
    "print(beta.shape)\n",
    "print(beta.iloc[0:5, 0:10])\n",
    "#beta.drop(beta.filter(regex=\"Unnamed\"),axis=1, inplace=True)\n",
    "print(\"Finish dropping column\")\n",
    "toc = time.process_time()\n",
    "print(beta.shape)\n",
    "print(toc-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start seed= 1\n",
      "1. Read files (seed=1)\n",
      "\tReading /Volumes/qtran/Semisupervised_Learning/python/data_class/seed1_70percLC.csv\n",
      "\tReading /Volumes/qtran/Semisupervised_Learning/python/data_class/seed1_35perc_LCgse109379.csv\n",
      "\tReading /Volumes/qtran/Semisupervised_Learning/python/data_class/seed1_70LC_gse109379.csv\n",
      "\tReading /Volumes/qtran/Semisupervised_Learning/python/data_class/seed1_70perc_gse109379LC.csv\n"
     ]
    }
   ],
   "source": [
    "n_split = 3\n",
    "n_repeat = 5\n",
    "rand = 123456\n",
    "rkfold = RepeatedStratifiedKFold(n_splits=n_split, n_repeats=n_repeat, random_state=rand)\n",
    "for seed in [1]:\n",
    "    print(\"start seed=\", seed)\n",
    "    result = evaluate(seed=seed, beta=beta, rkfold = rkfold, encoder=label_encoder, cls_weight = cls_weight_dict, sd_cutoff=0.3)\n",
    "    output_file = '/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/result_NN_balanced_LCClass_seed{}_GSE109379_rand{}.csv'.format(seed, rand)\n",
    "    output_per_class_file ='/research/rgs01/home/clusterHome/qtran/Semisupervised_Learning/python/output_acc_perClass/result_NN_bal_acc_perLCClass_seed{}_GSE109379_rand{}.csv'.format(seed, rand)\n",
    "    result[0].to_csv(output_file, index=False)\n",
    "    result[1].to_csv(output_per_class_file, index=False)\n",
    "    print('Result saved to', output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
