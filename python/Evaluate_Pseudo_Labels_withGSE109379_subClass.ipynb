{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Pseudo Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. Do labels obtained from semisupervised classifier improve a supervised classifier performance?\n",
    "2. Do high confident labels from a SSL model improve a supervised classifier performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "Original data set has 2801 samples x 5072 features. This data were split into 70% train and 30% test. This process was repeated 7 times to create 7 different train-test splits.\n",
    "\n",
    "For each split:\n",
    "1. Create a random forest model\n",
    "2. Evaluate the model on 35% data with itest\n",
    "3. Evaluate the model on 35% data  + SSL GSE109379 with itest\n",
    "4. Evaluate the model on 35% data + 35% pseudo-label data + GSE109379 pseudo-label data with itest\n",
    "5. Evaluate the model on 35% data + 35% pseudo-label data + HC GSE1093790 pseudo-label data with itest\n",
    "6. Evaluate the model on 35% data + high confident pseudo-label +  GSE109379 pseudo-label data with itest\n",
    "7. Evaluate the model on 35% data + high confident pseudo-label +  HC GSE109379 pseudo-label data with itest\n",
    "\n",
    "\n",
    "Box plots for each model (1 box plot show the average accuracies of each model over the 7 train-test splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, accuracy_score,f1_score,precision_score,recall_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "  # it returns a dictionary data structure whose \n",
    "# keys are array elements and values are their \n",
    "# corresponding frequencies {1: 4, 2: 4, 3: 2, \n",
    "# 5: 2, 4: 1}\n",
    "def CountFrequency(arr):\n",
    "    return collections.Counter(arr)  \n",
    "\n",
    "def combine(y, str):\n",
    "    freq = CountFrequency(y)\n",
    "    d = pd.DataFrame(freq.items(), columns=['Sample', 'pseudo_class_label'] )    \n",
    "    schema = [str] * len(d)\n",
    "    d['Dataset'] = schema\n",
    "    return d\n",
    "\n",
    "def get_freq_series(y):\n",
    "    freq = CountFrequency(y)\n",
    "    s = pd.Series(freq.values(), index = freq.keys())\n",
    "    return s\n",
    "    \n",
    "def read_Mat(filename):\n",
    "    d = scipy.io.loadmat(filename)\n",
    "    xtrain = d['xtrain']\n",
    "    ytrain = [x[0][0].strip() for x in d['ytrain']]\n",
    "    xitest = d['xitest']\n",
    "    yitest = [x[0][0].strip() for x in d['yitest']]\n",
    "    return(xtrain, ytrain, xitest, yitest)\n",
    "\n",
    "def get_beta_in_select_file(beta, filename):\n",
    "    X_temp, y = process_csv(filename)\n",
    "    X = beta[ X_temp.index ]\n",
    "    return X.T, y\n",
    " \n",
    "def process_csv(filename):\n",
    "    df = pd.read_csv(filename, index_col=0)\n",
    "    y = df.y\n",
    "    X = df.drop(columns=['y'])\n",
    "    return (X, y)\n",
    "\n",
    "def append_result(p, df):\n",
    "    s = pd.Series(p, index=df.columns)\n",
    "    return df.append(s, ignore_index=True)\n",
    "\n",
    "def select_probes(data, sd_cutoff):\n",
    "    probes = data.T\n",
    "    probes['STD'] = probes.std(axis=1)\n",
    "    above_threshold = probes[probes[\"STD\"] > sd_cutoff]\n",
    "    print(\"shape in select_probes\", above_threshold.T.shape)\n",
    "    return above_threshold.drop(columns='STD').T\n",
    "\n",
    "def match_probes(ref_data, data_to_be_matched):\n",
    "    df = data_to_be_matched.loc[:, ref_data.columns.values]\n",
    "    return df\n",
    "\n",
    "def apply_CV(mod, cv, X, y):\n",
    "    return cross_validate(mod, X, y, cv=cv, scoring=['balanced_accuracy', 'accuracy', 'recall_weighted'])\n",
    "\n",
    "def accuracy_per_class(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.unique(y_true)\n",
    "    per_class_accuracies = cm.diagonal()/cm.sum(axis=1)\n",
    "    per_class_acc_wKeys = {}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        per_class_acc_wKeys[cls] = per_class_accuracies[idx]\n",
    "    return per_class_acc_wKeys\n",
    "\n",
    "def evaluate_against_test_set(mod, x_train, y_train, x_test, y_test, cls_weight):\n",
    "    mod.fit(x_train, y_train)\n",
    "    y_pred = mod.predict(x_test)\n",
    "    test_sample_weights = class_weight.compute_sample_weight(cls_weight, y_test)\n",
    "    acc=accuracy_score(y_test,y_pred).round(3)\n",
    "    bal_acc=balanced_accuracy_score(y_test,y_pred, sample_weight = test_sample_weights).round(3)\n",
    "    rec=recall_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    prec=precision_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    f1=f1_score(y_test,y_pred, average='weighted').round(3)\n",
    "    per_class_acc = accuracy_per_class(y_test, y_pred)\n",
    "    return (acc, bal_acc, rec, prec, f1, per_class_acc)\n",
    "\n",
    "def evaluate_against_cv_test_set(mod, x_test, y_test, cls_weight):\n",
    "    y_pred = mod.predict(x_test)\n",
    "    test_sample_weights = class_weight.compute_sample_weight(cls_weight, y_test)\n",
    "    acc=accuracy_score(y_test,y_pred).round(3)\n",
    "    bal_acc=balanced_accuracy_score(y_test,y_pred, sample_weight = test_sample_weights).round(3)\n",
    "    rec=recall_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    prec=precision_score(y_test,y_pred, average='weighted', zero_division=0).round(3)\n",
    "    f1=f1_score(y_test,y_pred, average='weighted').round(3)\n",
    "    return (acc, bal_acc, rec, prec, f1)\n",
    "\n",
    "def cross_validate_withSD(mod, data_x, data_y, cv, sd_cutoff, cls_weight):\n",
    "    '''\n",
    "    features are selectiving for the training data set after each CV split\n",
    "    '''\n",
    "    #cvscores = []\n",
    "    cv_balanced_scores = []\n",
    "    fold = 1\n",
    "    #model = RandomForestClassifier(n_estimators = 50, max_depth=100)\n",
    "    for train_index,test_index in cv.split(data_x, data_y):\n",
    "        #print(\"X_cv shape = \", data_x.shape, \"; y_cv shape = \", data_y.shape)\n",
    "        x_train = select_probes(data_x.iloc[train_index, :], sd_cutoff)\n",
    "        x_test = match_probes(x_train, data_x.iloc[test_index, :])\n",
    "        \n",
    "        y_train,y_test = data_y[train_index], data_y[test_index]\n",
    "        \n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold} ...')\n",
    "        mod.fit(x_train, y_train)\n",
    "        scores = evaluate_against_cv_test_set(mod, x_test, y_test, cls_weight)\n",
    "    \n",
    "        cv_balanced_scores.append(scores)\n",
    "        \n",
    "        print(\"Scores = \", scores)\n",
    "        \n",
    "        fold = fold+1\n",
    "    return model, pd.DataFrame(cv_balanced_scores, columns= ['acc', 'bal_acc', 'weighted_recall','weighted_precision', 'weighted_F1'])\n",
    "\n",
    "\n",
    "def append_cv_results(df, r, seed_name, dataset_name):\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'accuracy', r['acc'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'balanced_acc', r['bal_acc'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'recall_weighted', r['weighted_recall'].mean()], df)\n",
    "    df = append_result([seed_name, dataset_name, 'cross_val', 'precision_weighted', r['weighted_precision'].mean()], df)\n",
    "    return df\n",
    "\n",
    "def accuracy_per_class(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.unique(y_true)\n",
    "    per_class_accuracies = cm.diagonal()/cm.sum(axis=1)\n",
    "    per_class_acc_wKeys = {}\n",
    "    for idx, cls in enumerate(classes):\n",
    "        per_class_acc_wKeys[cls] = per_class_accuracies[idx]\n",
    "    return per_class_acc_wKeys\n",
    "\n",
    "def append_testset_results(df, r, seed_name, dataset_name):\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'accuracy', r[0]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'balanced_acc', r[1]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'recall_weighted', r[2]], df)\n",
    "    df = append_result([seed_name, dataset_name, 'vs_testset', 'precision_weighted', r[3]], df)\n",
    "    return df\n",
    "\n",
    "def create_per_class_acc_df(class_acc, seed, dset):\n",
    "    d = pd.DataFrame(columns = ['Seed', 'Dataset'])\n",
    "    d = d.append(class_acc, ignore_index=True)\n",
    "    d['Seed'] = seed\n",
    "    d['Dataset'] = dset\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cm(y_true, y_pred):\n",
    "    # Creating  a confusion matrix,which compares the y_test and y_pred\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Creating a dataframe for a array-formatted Confusion matrix.\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                     index = np.unique(y_true), \n",
    "                     columns = np.unique(y_true))\n",
    "    #Plotting the confusion matrix\n",
    "    plt.figure(figsize=(19,25))\n",
    "    sns.heatmap(cm_df, annot=True, cmap=\"YlGnBu\", cbar_kws={\"orientation\": \"horizontal\"})\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Labels')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate(seed, model, cv, mcf=False):\n",
    "    print('1. Read files (seed={})'.format(seed))\n",
    "       \n",
    "    file35 = './data_class/seed{}_35perc.csv'.format(seed)\n",
    "    file70='./data_class/seed{}_70perc.csv'.format(seed)\n",
    "    file70HC= './data_class/seed{}_70percHC.csv'.format(seed)\n",
    "    \n",
    "    file35_GSE='./data_class/seed{}_35perc_gse109379.csv'.format(seed)\n",
    "    file35_GSEHC ='./data_class/seed{}_35perc_HCgse109379.csv'.format(seed)\n",
    "    file70_GSE = './data_class/seed{}_70perc_gse109379.csv'.format(seed)\n",
    "    \n",
    "    file70HC_GSE = './data_class/seed{}_70HC_gse109379.csv'.format(seed)\n",
    "    file70_GSEHC = './data_class/seed{}_70perc_gse109379HC.csv'.format(seed)\n",
    "    file70HC_GSEHC = './data_class/seed{}_70HC_gse109379HC.csv'.format(seed)\n",
    "    \n",
    "    \n",
    "    fileHoldOut = './data_class/seed{}_holdOutTest.csv'.format(seed)\n",
    "    #########\n",
    "    print('\\tReading', file35)\n",
    "    X35, y35 = process_csv(file35)\n",
    "    print('\\tReading', file70)\n",
    "    X70, y70 = process_csv(file70)\n",
    "    print('\\tReading', file70HC)\n",
    "    X70HC, y70HC = process_csv(file70HC)\n",
    "    \n",
    "    print('\\tReading', file35_GSE)\n",
    "    X35gse, y35gse = process_csv(file35_GSE)\n",
    "    print('\\tReading', file35_GSEHC)\n",
    "    X35gseHC, y35gseHC = process_csv(file35_GSEHC)\n",
    "    print('\\tReading', file70_GSE)\n",
    "    X70gse, y70gse = process_csv(file70_GSE)\n",
    "    \n",
    "    print('\\tReading', file70HC_GSE)\n",
    "    X70HCgse, y70HCgse = process_csv(file70HC_GSE)\n",
    "    print('\\tReading', file70_GSEHC)\n",
    "    X70gseHC, y70gseHC = process_csv(file70_GSEHC)\n",
    "    print('\\tReading', file70HC_GSEHC)\n",
    "    XHC, yHC = process_csv(file70HC_GSEHC)\n",
    "    \n",
    "    print('\\tReading', fileHoldOut)\n",
    "    xitest, yitest = process_csv(fileHoldOut)\n",
    "    ###################\n",
    "    \n",
    "    \n",
    "    print('2. Evaluate model with 35% data')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_35 = apply_CV(model, cv, X35, y35)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_35 = evaluate_against_test_set(model, X35, y35, xitest, yitest)\n",
    "          \n",
    "    print('3. Evaluate model with 70% data')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_70 = apply_CV(model, cv, X70, y70)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70 = evaluate_against_test_set(model, X70, y70, xitest, yitest)\n",
    "\n",
    "    print('4. Evaluate model with 70% HC')    \n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_70HC = apply_CV(model, cv, X70HC, y70HC)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70HC = evaluate_against_test_set(model, X70HC, y70HC, xitest, yitest)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    print('5. Evaluate model with 35% data with GSE109379')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_35gse = apply_CV(model, cv, X35gse, y35gse)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_35gse = evaluate_against_test_set(model, X35gse, y35gse, xitest, yitest)\n",
    "    \n",
    "    print('5. Evaluate model with 35% data with High confident GSE109379')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_35gseHC = apply_CV(model, cv, X35gseHC, y35gseHC)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_35gseHC = evaluate_against_test_set(model, X35gseHC, y35gseHC, xitest, yitest)\n",
    "    \n",
    "    print('6. Evaluate model with 70% + GSE90496 pseudo-labeled data')    \n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_70gse = apply_CV(model, cv, X70gse, y70gse)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70gse = evaluate_against_test_set(model, X70gse, y70gse, xitest, yitest)\n",
    "    \n",
    "    ##########    \n",
    "             \n",
    "    print('7. Evaluate model with 70% HC + GSE109379')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_70HCgse = apply_CV(model, cv, X70HCgse, y70HCgse)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70HCgse = evaluate_against_test_set(model, X70HCgse, y70HCgse, xitest, yitest)\n",
    "\n",
    "    print('8. Evaluate model with 70% + HC GSE90496 ')    \n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_70gseHC = apply_CV(model, cv, X70gseHC, y70gseHC)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70gseHC = evaluate_against_test_set(model, X70gseHC, y70gseHC, xitest, yitest)\n",
    "      \n",
    "    print('9. Evaluate model with HC pseudo-labeled data')    \n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    result_cv_HC = apply_CV(model, cv, XHC, yHC)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_HC = evaluate_against_test_set(model, XHC, yHC, xitest, yitest)\n",
    "\n",
    "    \n",
    "    print('6. Store results.')\n",
    "    df = pd.DataFrame(data=[], columns=['Seed','Dataset','Validation','Metric','Value'])\n",
    "    df = append_cv_results(df, result_cv_35, seed, '35')\n",
    "    df = append_testset_results(df, result_ts_35, seed, '35')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70, seed, '70')\n",
    "    df = append_testset_results(df, result_ts_70, seed, '70')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70HC, seed, '70HC')\n",
    "    df = append_testset_results(df, result_ts_70HC, seed, '70HC')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_35gse, seed, '35_GSE')\n",
    "    df = append_testset_results(df, result_ts_35gse, seed, '35_GSE')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_35gseHC, seed, '35_gseHC')\n",
    "    df = append_testset_results(df, result_ts_35gseHC, seed, '35_gseHC')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70gse, seed, '70_GSE')\n",
    "    df = append_testset_results(df, result_ts_70gse, seed, '70_GSE')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70HCgse, seed, '70HC_GSE')\n",
    "    df = append_testset_results(df, result_ts_70HCgse, seed, '70HC_GSE')\n",
    "    df = append_cv_results(df, result_cv_70gseHC, seed, '70_gseHC')\n",
    "    df = append_testset_results(df, result_ts_70gseHC, seed, '70_gseHC')\n",
    "    df = append_cv_results(df, result_cv_HC, seed, 'HC')\n",
    "    df = append_testset_results(df, result_ts_HC, seed, 'HC')\n",
    "    \n",
    "    #df_class_acc = pd.DataFrame(columns = ['Seed', 'Dataset'])\n",
    "    \n",
    "    df_class = create_per_class_acc_df(result_ts_35[3], seed, '35')\n",
    "    \n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70[3], seed, '70'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70HC[3], seed, '70HC'))\n",
    "    \n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_35gse[3], seed, '35GSE'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_35gseHC[3], seed, '35_gseHC'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70gse[3], seed, '70_GSE'))\n",
    "    \n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70HCgse[3], seed, '70HC_GSE'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_70gseHC[3], seed, '70_gseHC'))\n",
    "    df_class = df_class.append(create_per_class_acc_df(result_ts_HC[3], seed, 'HC'))\n",
    "    \n",
    "    return (df, df_class)\n",
    "\n",
    "def evaluate_short(seed, probe_data, model, cv, mcf=False):\n",
    "    print('1. Read files (seed={})'.format(seed))\n",
    "       \n",
    "    file35 = './data_class/seed{}_35perc.csv'.format(seed)\n",
    "    file70='./data_class/seed{}_70perc.csv'.format(seed)\n",
    "    file70HC= './data_class/seed{}_70percHC.csv'.format(seed)\n",
    "    \n",
    "    fileHoldOut = './data_class/seed{}_holdOutTest.csv'.format(seed)\n",
    "    #########\n",
    "    print('\\tReading', file35)\n",
    "    X35, y35 = get_beta_in_select_file(probe_data, file35)\n",
    "    print('\\tReading', file70)\n",
    "    X70, y70 = get_beta_in_select_file(probe_data, file70)\n",
    "    print('\\tReading', file70HC)\n",
    "    X70HC, y70HC = get_beta_in_select_file(probe_data, file70HC)\n",
    "    \n",
    "        \n",
    "    print('\\tReading', fileHoldOut)\n",
    "    xitest, yitest = get_beta_in_select_file(probe_data, fileHoldOut)\n",
    "    ###################\n",
    "    \n",
    "    \n",
    "    print('2. Evaluate model with 35% data')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    mod35, result_cv_35 = cross_validate_withSD(model, X35, y35, cv, sd_cutoff = 0.3, cls_weight = cls_weight_dict)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_35 = evaluate_against_test_set(mod35, X35, y35, xitest, yitest, cls_weight=cls_weight_dict)\n",
    "          \n",
    "    print('3. Evaluate model with 70% data')\n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    mod70, result_cv_70 = cross_validate_withSD(model, X70, y70, cv, sd_cutoff = 0.3, cls_weight = cls_weight_dict)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70 = evaluate_against_test_set(mod70, X70, y70, xitest, yitest, cls_weight=cls_weight_dict)\n",
    "\n",
    "    print('4. Evaluate model with 70% HC')    \n",
    "    print('\\tcross validate', model, 'with', cv)\n",
    "    mod70HC, result_cv_70HC = cross_validate_withSD(model, X70HC, y70HC, cv, sd_cutoff = 0.3, cls_weight = cls_weight_dict)\n",
    "    print('\\tvalidate against test set')\n",
    "    result_ts_70HC = evaluate_against_test_set(mod70HC, X70HC, y70HC, xitest, yitest, cls_weight=cls_weight_dict)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "        \n",
    "    print('6. Store results.')\n",
    "    df = pd.DataFrame(data=[], columns=['Seed','Dataset','Validation','Metric','Value'])\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_35, seed, '35')\n",
    "    df = append_testset_results(df, result_ts_35, seed, '35')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70, seed, '70')\n",
    "    df = append_testset_results(df, result_ts_70, seed, '70')\n",
    "    \n",
    "    df = append_cv_results(df, result_cv_70HC, seed, '70HC')\n",
    "    df = append_testset_results(df, result_ts_70HC, seed, '70HC')\n",
    "    \n",
    "    #df_class_acc = pd.DataFrame(columns = ['Seed', 'Dataset'])\n",
    "    \n",
    "    df_class_acc = create_per_class_acc_df(result_ts_35[5], seed, '35')\n",
    "    df_class_acc = df_class_acc.append(create_per_class_acc_df(result_ts_70[5], seed, '70'))\n",
    "    df_class_acc = df_class_acc.append(create_per_class_acc_df(result_ts_70HC[5], seed, '70HC'))\n",
    "       \n",
    "    return (df, df_class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Combine all the pseudo_label_inputs into 1 file \n",
    "def count_pseudo_label_per_class(seed):\n",
    "    print('1. Read files (seed={})'.format(seed))\n",
    "       \n",
    "    file35 = './data/seed{}_35perc.csv'.format(seed)\n",
    "    file70='./data/seed{}_70perc.csv'.format(seed)\n",
    "    file70HC= './data/seed{}_70percHC.csv'.format(seed)\n",
    "    \n",
    "    file35_GSE='./data/seed{}_35perc_gse109379.csv'.format(seed)\n",
    "    file35_GSEHC ='./data/seed{}_35perc_HCgse109379.csv'.format(seed)\n",
    "    file70_GSE = './data/seed{}_70perc_gse109379.csv'.format(seed)\n",
    "    \n",
    "    file70HC_GSE = './data/seed{}_70HC_gse109379.csv'.format(seed)\n",
    "    file70_GSEHC = './data/seed{}_70perc_gse109379HC.csv'.format(seed)\n",
    "    file70HC_GSEHC = './data/seed{}_70HC_gse109379HC.csv'.format(seed)\n",
    "    \n",
    "    fileHoldOut = './data/seed{}_holdOutTest.csv'.format(seed)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    print('\\tReading', file35)\n",
    "    X35, y35 = process_csv(file35)\n",
    "    f35 = get_freq_series(y35)\n",
    "    print('\\tReading', file70)\n",
    "    X70, y70 = process_csv(file70)\n",
    "    f70 = get_freq_series(y70)\n",
    "    print('\\tReading', file70HC)\n",
    "    X70HC, y70HC = process_csv(file70HC)\n",
    "    f70HC = get_freq_series(y70HC)\n",
    "    \n",
    "    print('\\tReading', file35_GSE)\n",
    "    X35gse, y35gse = process_csv(file35_GSE)\n",
    "    f35gse = get_freq_series(y35gse)\n",
    "    print('\\tReading', file35_GSEHC)\n",
    "    X35gseHC, y35gseHC = process_csv(file35_GSEHC)\n",
    "    f35gseHC = get_freq_series(y35gseHC)\n",
    "    print('\\tReading', file70_GSE)\n",
    "    X70gse, y70gse = process_csv(file70_GSE)\n",
    "    f70gse = get_freq_series(y70gse)\n",
    "    \n",
    "    print('\\tReading', file70HC_GSE)\n",
    "    X70HCgse, y70HCgse = process_csv(file70HC_GSE)\n",
    "    f70HCgse = get_freq_series(y70HCgse)\n",
    "    print('\\tReading', file70_GSEHC)\n",
    "    X70gseHC, y70gseHC = process_csv(file70_GSEHC)\n",
    "    f70gseHC = get_freq_series(y70gseHC)\n",
    "    print('\\tReading', file70HC_GSEHC)\n",
    "    XHC, yHC = process_csv(file70HC_GSEHC)\n",
    "    fHC = get_freq_series(yHC)\n",
    "    \n",
    "    print('\\tReading', fileHoldOut)\n",
    "    xitest, yitest = process_csv(fileHoldOut)\n",
    "    fitest = get_freq_series(yitest)\n",
    "    \n",
    " \n",
    "    print('2. Store pseudo_label_counts')\n",
    "    df = pandas.DataFrame(data=[], columns = f35.keys())\n",
    "    df = df.append(f35, ignore_index=True)\n",
    "    df = df.append(f70, ignore_index=True)  \n",
    "    df = df.append(f70HC, ignore_index=True)\n",
    "    df = df.append(f35gse, ignore_index=True)\n",
    "    df = df.append(f35gseHC, ignore_index=True)\n",
    "    df = df.append(f70gse, ignore_index=True)\n",
    "    df = df.append(f70HCgse, ignore_index=True)\n",
    "    df = df.append(f70gseHC, ignore_index=True)\n",
    "    df = df.append(fHC, ignore_index=True)\n",
    "    df = df.append(fitest, ignore_index=True)\n",
    "    \n",
    "    df.insert(0, 'Dataset', ['35', '70', '70HC', '35gse', '35gseHC', '70gse', '70HCgse', '70gseHC', 'HC', 'holdOut'])\n",
    "    df.insert(1, 'Seed', [seed]*10)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_seeds(rand):\n",
    "    model = RandomForestClassifier(n_estimators = 50, max_depth=100)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=5, random_state=rand)\n",
    "    for seed in [2, 20, 40, 80, 160, 320]:\n",
    "        result = evaluate(seed, beta, model, cv)\n",
    "        output_file = './output/result_subClass_seed{}_GSE109379_{}.csv'.format(seed, rand)\n",
    "        output_per_class_file = './output_acc_perClass/result_acc_perClass_seed{}_GSE109379_{}.csv'.format(seed, rand)\n",
    "        result[0].to_csv(output_file, index=False)\n",
    "        result[1].to_csv(output_per_class_file, index=False)\n",
    "        print('Result saved to', output_file)\n",
    "        \n",
    "def run_one_seeds(rand):\n",
    "    model = RandomForestClassifier(n_estimators = 50, max_depth=100, random_state=rand)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1)\n",
    "    for seed in [ 2]:\n",
    "        result = evaluate_short(seed, beta, model, cv)\n",
    "        output_file = './output/result_RF_subClass_seed{}_GSE109379_{}.csv'.format(seed, rand)\n",
    "        output_per_class_file = './output_acc_perClass/result_RF_acc_perClass_seed{}_GSE109379_{}.csv'.format(seed, rand)\n",
    "        result[0].to_csv(output_file, index=False)\n",
    "        result[1].to_csv(output_per_class_file, index=False)\n",
    "        print('Result saved to', output_file)\n",
    "        \n",
    "def create_pseudo_labels_file():\n",
    "    for seed in [1, 2, 20, 40, 80, 160, 320]:\n",
    "        combined_labels = count_pseudo_label_per_class(seed)\n",
    "        output_file = 'pseudo_label_subClass_seed{}.csv'.format(seed)\n",
    "        combined_labels.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_file = './raw_data/top32K_GSE90496.txt'\n",
    "beta = pd.read_csv(beta_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "file35 = './data_class/seed{}_35perc.csv'.format(seed)\n",
    "file70='./data_class/seed{}_70perc.csv'.format(seed)\n",
    "X35, y35 = get_beta_in_select_file(beta, file35)\n",
    "X70, y70 = get_beta_in_select_file(beta, file35)\n",
    "fileHoldOut = './data_class/seed{}_holdOutTest.csv'.format(seed)\n",
    "xitest, yitest = get_beta_in_select_file(beta, fileHoldOut)\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      y\n",
      "GSM2402854_5684819014_R03C02   GBM, G34\n",
      "GSM2402863_5684819013_R04C01   DMG, K27\n",
      "GSM2402953_6164621144_R03C02  ATRT, TYR\n",
      "GSM2403853_9305651003_R06C02  EPN, RELA\n",
      "GSM2403854_9305651005_R03C02  EPN, PF B\n",
      "...                                 ...\n",
      "GSM2403848_9305651037_R02C02   CPH, PAP\n",
      "GSM2403849_9305651037_R06C01   CPH, PAP\n",
      "GSM2403850_9305651037_R04C01   EPN, MPE\n",
      "GSM2403851_9305651037_R01C02      PITUI\n",
      "GSM2403852_9305651037_R06C02       SCHW\n",
      "\n",
      "[2801 rows x 1 columns]\n",
      "{'A IDH': 0.395, 'A IDH, HG': 0.669, 'ANA PA': 1.466, 'ATRT, MYC': 1.061, 'ATRT, SHH': 0.669, 'ATRT, TYR': 0.832, 'CHGL': 2.565, 'CHORDM': 3.42, 'CN': 1.466, 'CNS NB, FOXR2': 0.789, 'CONTR, ADENOPIT': 3.42, 'CONTR, CEBM': 3.848, 'CONTR, HEMI': 2.368, 'CONTR, HYPTHAL': 3.42, 'CONTR, INFLAM': 1.283, 'CONTR, PINEAL': 2.565, 'CONTR, PONS': 2.565, 'CONTR, REACT': 1.338, 'CONTR, WM': 3.42, 'CPH, ADM': 1.231, 'CPH, PAP': 1.539, 'DLGNT': 3.848, 'DMG, K27': 0.395, 'EFT, CIC': 2.368, 'ENB, A': 1.338, 'ENB, B': 1.924, 'EPN, MPE': 1.099, 'EPN, PF A': 0.338, 'EPN, PF B': 0.604, 'EPN, RELA': 0.44, 'EPN, SPINE': 1.14, 'EPN, YAP': 2.798, 'ETMR': 0.716, 'EWS': 2.199, 'GBM, G34': 0.751, 'GBM, MES': 0.55, 'GBM, MID': 2.199, 'GBM, MYCN': 1.924, 'GBM, RTK I': 0.481, 'GBM, RTK II': 0.215, 'GBM, RTK III': 2.368, 'HGNET, BCOR': 1.338, 'HGNET, MN1': 1.466, 'HMB': 1.231, 'IHG': 3.078, 'LGG, DIG DIA': 3.848, 'LGG, DNT': 0.7, 'LGG, GG': 1.466, 'LGG, MYB': 1.399, 'LGG, PA GG ST': 1.283, 'LGG, PA MID': 0.81, 'LGG, PA PF': 0.27, 'LGG, RGNT': 3.42, 'LGG, SEGA': 1.466, 'LIPN': 3.078, 'LYMPHO': 2.368, 'MB, G3': 0.4, 'MB, G4': 0.223, 'MB, SHH CHL AD': 0.366, 'MB, SHH INF': 0.592, 'MB, WNT': 0.789, 'MELAN': 2.565, 'MELCYT': 2.052, 'MNG': 0.342, 'O IDH': 0.385, 'PGG, nC': 1.62, 'PIN T, PB A': 3.42, 'PIN T, PB B': 1.399, 'PIN T, PPT': 1.62, 'PITAD, ACTH': 1.71, 'PITAD, FSH LH': 1.466, 'PITAD, PRL': 3.848, 'PITAD, STH DNS A': 3.42, 'PITAD, STH DNS B': 2.565, 'PITAD, STH SPA': 1.811, 'PITAD, TSH': 3.078, 'PITUI': 1.061, 'PLASMA': 3.848, 'PLEX, AD': 1.399, 'PLEX, PED A': 2.052, 'PLEX, PED B': 0.669, 'PTPR, A': 3.848, 'PTPR, B': 1.399, 'PXA': 0.7, 'RETB': 1.62, 'SCHW': 1.338, 'SCHW, MEL': 3.848, 'SFT HMPC': 1.924, 'SUBEPN, PF': 0.832, 'SUBEPN, SPINE': 3.42, 'SUBEPN, ST': 1.62}\n"
     ]
    }
   ],
   "source": [
    "class_label = './raw_data/GSE90496_methylation_class_label.csv'\n",
    "\n",
    "labels = pd.read_csv(class_label, header=0, names=['y'])\n",
    "print(labels)\n",
    "cls_weights = class_weight.compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels['y'])\n",
    "\n",
    "cls_weight_dict = {}\n",
    "i = 0\n",
    "for cls in np.unique(labels):\n",
    "    cls_weight_dict[cls] = cls_weights[i].round(3)\n",
    "    i = i+1\n",
    "print(cls_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Read files (seed=2)\n",
      "\tReading ./data_class/seed2_35perc.csv\n",
      "\tReading ./data_class/seed2_70perc.csv\n",
      "\tReading ./data_class/seed2_70percHC.csv\n",
      "\tReading ./data_class/seed2_holdOutTest.csv\n",
      "2. Evaluate model with 35% data\n",
      "\tcross validate RandomForestClassifier(max_depth=100, n_estimators=50, random_state=123456) with RepeatedStratifiedKFold(n_repeats=1, n_splits=2, random_state=None)\n",
      "shape in select_probes (488, 4081)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Scores =  (0.795, 0.648, 0.795, 0.764, 0.765)\n",
      "shape in select_probes (488, 4176)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Scores =  (0.778, 0.596, 0.778, 0.734, 0.736)\n",
      "\tvalidate against test set\n",
      "3. Evaluate model with 70% data\n",
      "\tcross validate RandomForestClassifier(max_depth=100, n_estimators=50, random_state=123456) with RepeatedStratifiedKFold(n_repeats=1, n_splits=2, random_state=None)\n",
      "shape in select_probes (981, 4162)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Scores =  (0.896, 0.783, 0.896, 0.882, 0.878)\n",
      "shape in select_probes (981, 3999)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Scores =  (0.893, 0.791, 0.893, 0.888, 0.88)\n",
      "\tvalidate against test set\n",
      "4. Evaluate model with 70% HC\n",
      "\tcross validate RandomForestClassifier(max_depth=100, n_estimators=50, random_state=123456) with RepeatedStratifiedKFold(n_repeats=1, n_splits=2, random_state=None)\n",
      "shape in select_probes (869, 4377)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Scores =  (0.869, 0.712, 0.869, 0.848, 0.846)\n",
      "shape in select_probes (869, 4232)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Scores =  (0.877, 0.742, 0.877, 0.86, 0.858)\n",
      "\tvalidate against test set\n",
      "6. Store results.\n",
      "TEst result (0.895, 0.8, 0.895, 0.88, 0.878, {'A IDH': 1.0, 'A IDH, HG': 0.7142857142857143, 'ANA PA': 0.5, 'ATRT, MYC': 0.8888888888888888, 'ATRT, SHH': 0.8571428571428571, 'ATRT, TYR': 1.0, 'CHGL': 1.0, 'CHORDM': 0.0, 'CN': 1.0, 'CNS NB, FOXR2': 1.0, 'CONTR, ADENOPIT': 1.0, 'CONTR, CEBM': 0.5, 'CONTR, HEMI': 1.0, 'CONTR, HYPTHAL': 1.0, 'CONTR, INFLAM': 1.0, 'CONTR, PINEAL': 1.0, 'CONTR, PONS': 1.0, 'CONTR, REACT': 0.8571428571428571, 'CONTR, WM': 1.0, 'CPH, ADM': 1.0, 'CPH, PAP': 1.0, 'DLGNT': 0.0, 'DMG, K27': 1.0, 'EFT, CIC': 0.75, 'ENB, A': 1.0, 'ENB, B': 0.6, 'EPN, MPE': 1.0, 'EPN, PF A': 1.0, 'EPN, PF B': 1.0, 'EPN, RELA': 1.0, 'EPN, SPINE': 0.875, 'EPN, YAP': 0.3333333333333333, 'ETMR': 1.0, 'EWS': 0.75, 'GBM, G34': 1.0, 'GBM, MES': 0.47058823529411764, 'GBM, MID': 0.0, 'GBM, MYCN': 0.2, 'GBM, RTK I': 0.8421052631578947, 'GBM, RTK II': 0.8837209302325582, 'GBM, RTK III': 0.0, 'HGNET, BCOR': 1.0, 'HGNET, MN1': 1.0, 'HMB': 1.0, 'IHG': 0.3333333333333333, 'LGG, DIG DIA': 1.0, 'LGG, DNT': 1.0, 'LGG, GG': 1.0, 'LGG, MYB': 1.0, 'LGG, PA GG ST': 0.8571428571428571, 'LGG, PA MID': 0.8181818181818182, 'LGG, PA PF': 1.0, 'LGG, RGNT': 0.0, 'LGG, SEGA': 0.8333333333333334, 'LIPN': 1.0, 'LYMPHO': 1.0, 'MB, G3': 0.9565217391304348, 'MB, G4': 1.0, 'MB, SHH CHL AD': 1.0, 'MB, SHH INF': 0.9375, 'MB, WNT': 1.0, 'MELAN': 0.75, 'MELCYT': 0.8, 'MNG': 1.0, 'O IDH': 0.9583333333333334, 'PGG, nC': 1.0, 'PIN T, PB A': 0.0, 'PIN T, PB B': 1.0, 'PIN T, PPT': 1.0, 'PITAD, ACTH': 1.0, 'PITAD, FSH LH': 1.0, 'PITAD, PRL': 0.0, 'PITAD, STH DNS A': 0.3333333333333333, 'PITAD, STH DNS B': 0.75, 'PITAD, STH SPA': 1.0, 'PITAD, TSH': 0.0, 'PITUI': 1.0, 'PLASMA': 1.0, 'PLEX, AD': 1.0, 'PLEX, PED A': 0.6, 'PLEX, PED B': 1.0, 'PTPR, A': 0.5, 'PTPR, B': 1.0, 'PXA': 1.0, 'RETB': 1.0, 'SCHW': 0.8571428571428571, 'SCHW, MEL': 0.5, 'SFT HMPC': 0.2, 'SUBEPN, PF': 1.0, 'SUBEPN, SPINE': 1.0, 'SUBEPN, ST': 0.8333333333333334})\n",
      "df class=    Seed Dataset  A IDH  A IDH, HG  ANA PA  ATRT, MYC  ATRT, SHH  ATRT, TYR  \\\n",
      "0     2      35    1.0   0.714286     0.5   0.888889   0.857143        1.0   \n",
      "\n",
      "   CHGL  CHORDM  ...  PTPR, A  PTPR, B  PXA  RETB      SCHW  SCHW, MEL  \\\n",
      "0   1.0     0.0  ...      0.5      1.0  1.0   1.0  0.857143        0.5   \n",
      "\n",
      "   SFT HMPC  SUBEPN, PF  SUBEPN, SPINE  SUBEPN, ST  \n",
      "0       0.2         1.0            1.0    0.833333  \n",
      "\n",
      "[1 rows x 93 columns]\n",
      "Result saved to ./output/result_RF_subClass_seed2_GSE109379_123456.csv\n"
     ]
    }
   ],
   "source": [
    "rand = 123456\n",
    "model = RandomForestClassifier(n_estimators = 100, max_depth=100)\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=5, random_state=rand)\n",
    "\n",
    "#y_pred = model.predict(xitest)\n",
    "#result_ts_35 = evaluate_against_test_set(model, X35, y35, xitest, yitest)\n",
    "\n",
    "run_one_seeds(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape in select_probes (650, 3873)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Scores =  (0.874, 0.733, 0.874, 0.839, 0.843)\n",
      "shape in select_probes (650, 3945)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Scores =  (0.862, 0.751, 0.862, 0.836, 0.834)\n",
      "shape in select_probes (651, 4230)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Scores =  (0.836, 0.738, 0.836, 0.805, 0.811)\n",
      "shape in select_probes (650, 4087)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Scores =  (0.883, 0.82, 0.883, 0.871, 0.866)\n",
      "shape in select_probes (650, 4038)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Scores =  (0.834, 0.701, 0.834, 0.791, 0.797)\n",
      "shape in select_probes (651, 3955)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Scores =  (0.87, 0.745, 0.87, 0.831, 0.841)\n",
      "shape in select_probes (650, 3895)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Scores =  (0.855, 0.718, 0.855, 0.82, 0.828)\n",
      "shape in select_probes (650, 4283)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Scores =  (0.846, 0.72, 0.846, 0.814, 0.819)\n",
      "shape in select_probes (651, 3872)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Scores =  (0.858, 0.757, 0.858, 0.831, 0.835)\n",
      "shape in select_probes (650, 4095)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Scores =  (0.865, 0.785, 0.865, 0.844, 0.844)\n",
      "shape in select_probes (650, 3909)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 11 ...\n",
      "Scores =  (0.855, 0.756, 0.855, 0.834, 0.829)\n",
      "shape in select_probes (651, 4056)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 12 ...\n",
      "Scores =  (0.861, 0.737, 0.861, 0.825, 0.832)\n",
      "shape in select_probes (650, 3812)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 13 ...\n",
      "Scores =  (0.837, 0.712, 0.837, 0.81, 0.812)\n",
      "shape in select_probes (650, 4081)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 14 ...\n",
      "Scores =  (0.834, 0.714, 0.834, 0.815, 0.803)\n",
      "shape in select_probes (651, 4178)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 15 ...\n",
      "Scores =  (0.864, 0.75, 0.864, 0.829, 0.834)\n"
     ]
    }
   ],
   "source": [
    "mod, cv_result = cross_validate_withSD(model, X35, y35, cv, sd_cutoff = 0.3, cls_weight = cls_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=50, random_state=1235)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidate against test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1814: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    }
   ],
   "source": [
    "result_cv_35 = apply_CV(model, cv, X35, y35)\n",
    "print('\\tvalidate against test set')\n",
    "model.fit(x_train, y35)\n",
    "y_pred = model.predict(xitest)\n",
    "result_ts_35 = evaluate_against_test_set(model, X35, y35, xitest, yitest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([8.97381186, 8.54711795, 8.71060991]),\n",
       " 'score_time': array([0.14942813, 0.14501619, 0.14842224]),\n",
       " 'test_balanced_accuracy': array([0.7355868 , 0.68504777, 0.65920009]),\n",
       " 'test_accuracy': array([0.85846154, 0.81538462, 0.80246914]),\n",
       " 'test_recall_weighted': array([0.85846154, 0.81538462, 0.80246914])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DLGNT',\n",
       " 'GBM, MYCN',\n",
       " 'GBM, RTK III',\n",
       " 'LGG, DIG DIA',\n",
       " 'LGG, RGNT',\n",
       " 'PIN T, PB A',\n",
       " 'PITAD, PRL',\n",
       " 'PITAD, STH DNS A',\n",
       " 'PTPR, A',\n",
       " 'SCHW, MEL'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.unique(y35)).difference(np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Read files (seed=1)\n",
      "\tReading ./data_class/seed1_35perc.csv\n",
      "\tReading ./data_class/seed1_70perc.csv\n",
      "\tReading ./data_class/seed1_70percHC.csv\n",
      "\tReading ./data_class/seed1_holdOutTest.csv\n",
      "2. Evaluate model with 35% data\n",
      "\tcross validate RandomForestClassifier(max_depth=100, n_estimators=50, random_state=1235) with RepeatedStratifiedKFold(n_repeats=1, n_splits=3, random_state=None)\n",
      "\tvalidate against test set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 32000 and input n_features is 5072 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f79e1e9f1df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_short\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-4c5918fbc2b3>\u001b[0m in \u001b[0;36mevaluate_short\u001b[0;34m(seed, probe_data, model, cv, mcf)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mresult_cv_35\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tvalidate against test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mresult_ts_35\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_against_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxitest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myitest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3. Evaluate model with 70% data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-4c5918fbc2b3>\u001b[0m in \u001b[0;36mevaluate_against_test_set\u001b[0;34m(mod, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_against_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mper_class_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_per_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \"\"\"\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 32000 and input n_features is 5072 "
     ]
    }
   ],
   "source": [
    "cv_result, test_result = evaluate_short(seed, beta, model, cv, mcf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
